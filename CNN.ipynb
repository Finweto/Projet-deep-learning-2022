{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[{"file_id":"1xLFNAWBJxmp0GBcRhmwKfZUbewBDq4hz","timestamp":1637764472783},{"file_id":"1wS56Bvj0KNGqMHIviwd2Y9uwYnUYkT5b","timestamp":1570893367950},{"file_id":"14MjAMPKQD3LIncUn2YEHJ3fBq8K2upuq","timestamp":1558960238747}],"collapsed_sections":["VbswqLLSgMzK","c6jAWFPyP85p","eGazvkPxP0oX"],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","metadata":{"id":"Be5uBRdgbhey"},"source":["# CNNs avec Keras sur des données de paysage"]},{"cell_type":"markdown","metadata":{"id":"7-diCsctWfSh"},"source":["## Vérification de l'utilisation de GPU\n","\n","Allez dans le menu `Exécution > Modifier le type d'execution` et vérifiez que l'on est bien en Python 3 et que l'accélérateur matériel est configuré sur « GPU »."]},{"cell_type":"code","metadata":{"id":"-S9vf7TtjjMa"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BW2_sMt8cSP-"},"source":["## Téléchargement du dataset Landscape depuis un repo git"]},{"cell_type":"code","metadata":{"id":"TZXdRwk2Lq3i"},"source":["!git clone https://github.com/nzmonzmp/dataset-landscape.git\n","!ls dataset-landscape\n","print(\"***\")\n","!ls -l dataset-landscape/seg_train\n","print(\"***\")\n","!ls -l dataset-landscape/seg_pred"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N5hheTPDcdqN"},"source":["## Import de TensorFlow et des autres librairies nécessaires"]},{"cell_type":"code","metadata":{"id":"SvZJ4yH6cNHE"},"source":["import itertools\n","import os\n","import pathlib\n","import random\n","import typing\n","\n","import cv2\n","import matplotlib.pyplot as plt\n","import numpy\n","import pandas\n","import seaborn\n","import sklearn.utils\n","import sklearn.metrics\n","import tensorflow.keras as keras"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9zCSZcuhczAn"},"source":["## Préparation des données\n","\n","Pour charger nos données, nous allons combiner plusieurs libraires : [OpenCV](https://opencv.org/), [NumPy](https://numpy.org/) et [scikit-learn](https://scikit-learn.org/stable/). Ces librairies seront appelées depuis la fonction `get_images`.\n","\n","Après avoir chargé chaque image, nous allons passer leur canaux en RGB puis les redimensionner à 150x150, enfin, par défaut, nous retournerons un dataset mélangé grâce à [`sklearn.utils.shuffle`](https://scikit-learn.org/stable/modules/generated/sklearn.utils.shuffle.html).\n","\n","*Complétez la fonction `get_images` qui va chercher les images dans `dir_path` contenant un dossier par classe. Chaque dossier de classe contient l'ensemble des images de cette classe. Il vous faut attribuer le label correct à chaque image.*"]},{"cell_type":"markdown","metadata":{"id":"VbswqLLSgMzK"},"source":["## Solution"]},{"cell_type":"code","metadata":{"id":"-kv62rzC3wIO"},"source":["label_names = [\"buildings\", \"forest\", \"glacier\", \"mountain\", \"sea\", \"street\"]\n","label_to_index = {l: i for i, l in enumerate(label_names)}\n","\n","\n","def get_images(dir_path: pathlib.Path, shuffle: bool = True\n","              ) -> typing.Tuple[numpy.ndarray, numpy.ndarray, numpy.ndarray]:\n","  images = []\n","  labels = []\n","  file_paths  = []\n","\n","  # On itère sur les sous-dossier de la racine : ils correspondent chacun à une\n","  # classe\n","  for subdir_path in dir_path.iterdir():\n","\n","    # Attribuez le bon label en fonction du nom du dossier \"labels\"\n","    # Votre code ici\n","    label = label_to_index.get(subdir_path.name)\n","\n","    # On ajoute chaque image du label (dossier) courant à notre dataset\n","    for image_path in subdir_path.iterdir():\n","      # Utilisation de OpenCV pour charger l'image\n","      image = cv2.imread(str(image_path))\n","      image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","      # En entrée d'un CNN, toutes les images doivent faire la même taille\n","      image = cv2.resize(image, (150, 150))\n","      images.append(image)\n","      labels.append(label)\n","      file_paths.append(image_path)\n","  images, labels, file_paths = map(numpy.array, [images, labels, file_paths])\n","\n","  # Mélange de ces tableaux\n","  if shuffle:\n","    images, labels, file_paths = sklearn.utils.shuffle(images,\n","                                                       labels,\n","                                                       file_paths)\n","  return images, labels, file_paths\n","\n","\n","# get_images(pathlib.Path(\"dataset-landscape\") / \"seg_train\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"12Co3AuagRdQ"},"source":["## Appel à `get_images`"]},{"cell_type":"code","metadata":{"id":"mlWHQMqbgUi_"},"source":["images, labels, file_paths = get_images(\n","    pathlib.Path(\"dataset-landscape\") / \"seg_train\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z9CFPgYahZ-_"},"source":["print(f\"Forme des images : {images.shape}\")\n","print(f\"Forme des labels : {labels.shape}\")\n","print(f\"Forme des chemins : {file_paths.shape}\")\n","\n","seaborn.countplot(x=labels)\n","plt.title(\"Décomptes des différents labels\")\n","plt.ylabel(\"Décompte\")\n","plt.xlabel(\"Label\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hRP8sepdhh8I"},"source":["# Création de la grille de sous-plots. On donne l'argument figsize pour agrandir\n","# la taille de la figure qui est petite par défaut\n","f, ax = plt.subplots(5, 5, figsize=(15, 15))\n","\n","# On choisit 25 indices au hasard, sans replacement (on ne veut pas afficher la\n","# même image deux fois)\n","random_indexes = numpy.random.choice(images.shape[0],\n","                                     size=(5, 5),\n","                                     replace=False)\n","\n","for i in range(5):\n","  for j in range(5):\n","    img_index = random_indexes[i, j]\n","    image = images[img_index]\n","    label = label_names[labels[img_index]]\n","\n","    # Affichage avec matplotlib et sa fonction imshow, très pratique en vision par\n","    # ordinateur\n","    ax[i, j].imshow(image)\n","    ax[i, j].set_title(f\"Exemple {img_index} ({label})\")\n","    ax[i, j].axis('off')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8JOKqXxDP5jB"},"source":["## Création du modèle\n","\n","Voici un exemple de CNN « minimaliste »"]},{"cell_type":"code","metadata":{"id":"qFvhX0LZjZw3"},"source":["# Initialisation et définition du modéle\n","\n","# Le modèle est un empilement de couches où le flux de données est séquentiel\n","model = keras.models.Sequential()\n","# Une première couche de 1 convolutions de 3x3 pixels\n","model.add(keras.layers.Conv2D(1,\n","                              kernel_size=(3, 3),\n","                              activation=\"relu\",\n","                              input_shape=(150, 150, 3)))\n","# Une couche de max pooling\n","model.add(keras.layers.MaxPool2D(3,3))\n","\n","# Une couche de manipulation des tenseurs : suppression de toutes les dimensions\n","# sauf celle de batch et une autre qui contient toutes les valeurs\n","model.add(keras.layers.Flatten())\n","\n","# Une couche de sortie dense avec 6 neurones et un softmax comme activation\n","model.add(keras.layers.Dense(6, activation=\"softmax\"))\n","\n","# Compilation du modèle avec la définition de la fonction de perte\n","model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n","              loss=\"sparse_categorical_crossentropy\",\n","              metrics=[\"accuracy\"])\n","\n","# Affichage d'un résumé du modèle\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AYBPo9koUi7k"},"source":["## Pouvez-vous expliquer les différents nombres de paramètres ?"]},{"cell_type":"markdown","metadata":{"id":"c6jAWFPyP85p"},"source":["### Solution\n"]},{"cell_type":"markdown","metadata":{"id":"EaRo4VICP_mh"},"source":["Premier layer de 1 convolutions : (taille du kernel) * (nb kernel) * (nb canaux en entrée) + (nb biais (= nb kernel)) = (3 * 3 ) * 1 * 3 + 1\n","\n","Dernier layer dense : (input dim) * (output dim) + (nb biais) = 2401 * 6 + 6\n","\n"]},{"cell_type":"markdown","metadata":{"id":"woNSPikeU_xl"},"source":["## Apprentissage\n","\n","Apprenons ce modèle sur nos données ! Dans un premier temps, nous entraînons sur une seule epoch pour simplement vérifier que notre modèle est opérationnel."]},{"cell_type":"code","metadata":{"id":"-vg7kkCCiyB_"},"source":["# Apprentissage du modèle\n","training_history = model.fit(images, labels, epochs=1, validation_split=0.30)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3ffuXmAvTuqF"},"source":["## Améliorez cette performance\n","\n","Inspirez-vous du modèle précédent en rajoutant des couches, en faisant des couches plus petites ou plus grosses.\n","\n","Visez entre 10 et 20 itérations et mois de 1 minute par itération (pour des raisons évidentes).\n","\n","On peut considérer l'utilisation d'une couche de dropout juste avant la dernière couche dense pour améliorer la régularisation.\n","\n","On peut obtenir une précision supérieure à 70% sur la base de validation en un temps raisonnable.\n","\n","La solution proposée prend $\\approx$ 45 secondes par itération pendant 15 itérations et atteint aux alentour de 85% d'accuracy sur la base de validation."]},{"cell_type":"code","metadata":{"id":"K-j7dwcWUdZx"},"source":["# Vos améliorations ici\n","model = keras.models.Sequential()\n","model.add(keras.layers.Conv2D(10,\n","                              kernel_size=(3, 3),\n","                              activation=\"relu\",\n","                              input_shape=(150, 150, 3)))\n","model.add(keras.layers.MaxPool2D(3,3))\n","model.add(keras.layers.Flatten())\n","model.add(keras.layers.Dense(6, activation=\"softmax\"))\n","model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n","              loss=\"sparse_categorical_crossentropy\",\n","              metrics=[\"accuracy\"])\n","\n","# Affichage d'un résumé du modèle\n","model.summary()\n","\n","# Apprentissage du modèle\n","training = model.fit(images, labels, epochs=10, validation_split=0.30)\n","\n","\n","# Plot des métriques d'entraînement\n","def plot_metrics(history) -> None:\n","  plt.plot(training.history[\"accuracy\"])\n","  plt.plot(training.history[\"val_accuracy\"])\n","  plt.title(\"Accuracy du modèle\")\n","  plt.ylabel(\"Accuracy\")\n","  plt.xlabel(\"Epoch\")\n","  plt.legend([\"Entraînement\", \"Validation\"], loc=\"upper left\")\n","  plt.show()\n","\n","  plt.plot(training.history[\"loss\"])\n","  plt.plot(training.history[\"val_loss\"])\n","  plt.title(\"Perte du modèle\")\n","  plt.ylabel(\"Perte\")\n","  plt.xlabel(\"Epoch\")\n","  plt.legend([\"Entraînement\", \"Validation\"], loc=\"upper right\")\n","  plt.show()\n","\n","\n","plot_metrics(training.history)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eGazvkPxP0oX"},"source":["### Solution"]},{"cell_type":"code","metadata":{"id":"8bIuRTZYAnWR"},"source":["conv2d_params = dict(kernel_size=(3,3),\n","                     activation=\"relu\",\n","                     kernel_initializer=\"orthogonal\",\n","                     padding=\"same\")\n","\n","dense_params = dict(activation=\"relu\", kernel_initializer=\"orthogonal\")\n","\n","model = keras.models.Sequential()\n","model.add(keras.layers.Conv2D(200, input_shape=(150, 150, 3), **conv2d_params))\n","model.add(keras.layers.MaxPool2D(2, 2, padding=\"same\"))\n","model.add(keras.layers.Conv2D(200, **conv2d_params))\n","model.add(keras.layers.MaxPool2D(2, 2, padding=\"same\"))\n","model.add(keras.layers.Conv2D(200, **conv2d_params))\n","model.add(keras.layers.MaxPool2D(2, 2, padding=\"same\"))\n","model.add(keras.layers.Conv2D(200, **conv2d_params))\n","model.add(keras.layers.MaxPool2D(2, 2, padding=\"same\"))\n","model.add(keras.layers.Conv2D(200, **conv2d_params))\n","model.add(keras.layers.MaxPool2D(2, 2, padding=\"same\"))\n","model.add(keras.layers.Conv2D(200, **conv2d_params))\n","model.add(keras.layers.MaxPool2D(2, 2, padding=\"same\"))\n","model.add(keras.layers.Conv2D(200, **conv2d_params))\n","model.add(keras.layers.Flatten())\n","model.add(keras.layers.Dropout(rate=0.2))\n","model.add(keras.layers.Dense(200, **dense_params))\n","model.add(keras.layers.Dropout(rate=0.2))\n","model.add(keras.layers.Dense(100, **dense_params))\n","model.add(keras.layers.Dropout(rate=0.2))\n","model.add(keras.layers.Dense(50, **dense_params))\n","model.add(keras.layers.Dropout(rate=0.2))\n","model.add(keras.layers.Dense(6,\n","                             activation=\"softmax\",\n","                             kernel_initializer=\"orthogonal\"))\n","\n","model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n","              loss=\"sparse_categorical_crossentropy\",\n","              metrics=[\"accuracy\"])\n","\n","# Affichage d'un résumé du modèle\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3PsIIXF0hzy5"},"source":["# Apprentissage du modèle\n","training = model.fit(images,\n","                     labels,\n","                     epochs=15,\n","                     validation_split=0.30,\n","                     batch_size=128)\n","\n","# Visualisation des métriques d'entrainement\n","plot_metrics(training.history)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hb_IT9QWeYPh"},"source":["## Évaluation des performances sur l'ensemble de test\n","\n","Dans le dossier `seg_test` se trouve un ensemble de données qui n'ont jamais été vues durant l'apprentissage.\n","\n","On utilisera la méthode `evaluate(X, y)` du modèle pour évaluer la qualité de nos prédictions sur ce dataset."]},{"cell_type":"code","metadata":{"id":"pJubx-J7i882"},"source":["test_images,test_labels, test_file_paths = get_images(\n","    pathlib.Path(\"dataset-landscape\") / \"seg_test\")\n","model.evaluate(test_images, test_labels, verbose=1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RYPaPc0lpe0B"},"source":["## Analyse d'erreur\n","\n","On affiche la matrice de confusion puis on regarde des images mal classées."]},{"cell_type":"code","metadata":{"id":"mfOlRq1Ep3KD"},"source":["def analyze_preds(preds, labels):\n","  confusion_matrix = sklearn.metrics.confusion_matrix(preds,\n","                                                      labels,\n","                                                      normalize=\"true\")\n","  seaborn.heatmap(confusion_matrix,\n","                  cmap=\"rocket_r\",\n","                  xticklabels=label_names,\n","                  yticklabels=label_names)\n","  plt.title(\"Matrice de confusion\")\n","  plt.show()\n","\n","  seaborn.countplot(x=list(map(lambda x: label_names[x], preds)))\n","  plt.title(\"Décomptes des classes prédites\")\n","  plt.ylabel(\"Décompte\")\n","  plt.xlabel(\"Class\")\n","  plt.show()\n","\n","\n","test_pred = numpy.argmax(model.predict(test_images), axis=-1)\n","analyze_preds(test_pred, test_labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hLUCp97BeUxu"},"source":["def plot_mistakes(predicted_class: str, true_class: str) -> None:\n","  print(f\"Prédiction : {predicted_class}, classe réelle : {true_class}\")\n","  mistakes = test_images[(test_pred == label_to_index[predicted_class])\n","                         & (test_labels == label_to_index[true_class])]\n","  random_indexes = numpy.random.choice(mistakes.shape[0],\n","                                       size=min(mistakes.shape[0], 25),\n","                                       replace=False)\n","  grid_indexes = itertools.product(range(5), repeat=2)\n","\n","  _, ax = plt.subplots(5, 5, figsize=(15, 15))\n","  for img_index, (i, j) in zip(random_indexes, grid_indexes):\n","    ax[i, j].imshow(mistakes[img_index])\n","    ax[i, j].axis(\"off\")\n","  plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"43kc6Wgd9bkC"},"source":["# Plot les images prédites glacier alors qu'elles ont un label montagne\n","plot_mistakes(\"glacier\", \"mountain\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_QyUe_6T_vL8"},"source":["# Plot les images prédites glacier alors qu'elles ont un label mer\n","plot_mistakes(\"glacier\", \"sea\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eAgJItMSDE2-"},"source":["# Plot les images prédites bâtiment alors qu'elles ont un label mer\n","plot_mistakes(\"buildings\", \"sea\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5VrH5FRb_OBy"},"source":["## Transfert d'apprentissage"]},{"cell_type":"code","metadata":{"id":"QCDC0Hw6_Qrn"},"source":["base_model = keras.applications.EfficientNetB7(include_top=False,\n","                                               weights=\"imagenet\",\n","                                               input_shape=(150, 150, 3))\n","\n","base_model.trainable = False\n","\n","model = keras.Sequential(\n","    [base_model,\n","     keras.layers.SpatialDropout2D(0.1),\n","     keras.layers.Conv2D(1024, 1, activation=\"relu\"),\n","     keras.layers.SpatialDropout2D(0.1),\n","     keras.layers.Conv2D(256, 1, activation=\"relu\"),\n","     keras.layers.SpatialDropout2D(0.1),\n","     keras.layers.Conv2D(64, 1, activation=\"relu\"),\n","     keras.layers.SpatialDropout2D(0.1),\n","     keras.layers.Conv2D(16, 1, activation=\"relu\"),\n","     keras.layers.SpatialDropout2D(0.1),\n","     keras.layers.Flatten(),\n","     keras.layers.Dense(6, activation=\"softmax\", kernel_regularizer=\"l2\")])\n","\n","model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n","              loss=\"sparse_categorical_crossentropy\",\n","              metrics=[\"accuracy\"])\n","\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uzYvqXA6A4_b"},"source":["training = model.fit(images,\n","                     labels,\n","                     epochs=5,\n","                     validation_split=0.30,\n","                     batch_size=512)\n","\n","plot_metrics(training.history)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9W-qBnuTAegR"},"source":["model.evaluate(test_images, test_labels, verbose=1)\n","test_preds = numpy.argmax(model.predict(test_images), axis=-1)\n","analyze_preds(test_preds, test_labels)\n","plot_mistakes(\"glacier\", \"mountain\")\n","plot_mistakes(\"glacier\", \"sea\")\n","plot_mistakes(\"buildings\", \"sea\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v4Q5NiBKjO6X"},"source":["## Prédire dans des condition « réelles »\n","\n","Dans le dossier `seg_pred` se trouvent des images non-annotées. On ne peut donc pas évaluer correctement les performances sur cet ensemble. \n","\n","Cependant, on peut afficher des photos et les probabilités que notre modèle attribue à chaque classe."]},{"cell_type":"code","metadata":{"id":"7yPf4WcytFzQ"},"source":["pred_images, _, pred_file_paths = get_images(\n","    pathlib.Path(\"dataset-landscape\") / \"seg_pred\")\n","pred_images.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iMLmuIqvWAS6"},"source":["# Création de la grille de sous-plots. On donne l'argument figsize pour agrandir\n","# la taille de la figure qui est petite par défaut\n","_, ax = plt.subplots(10, 5, figsize=(30, 45))\n","\n","# On choisit 25 indices au hasard, sans replacement (on ne veut pas afficher la\n","# même image deux fois)\n","random_indexes = numpy.random.choice(pred_images.shape[0],\n","                                     size=(5, 5),\n","                                     replace=False)\n","\n","for i in range(5):\n","  for j in range(5):\n","    img_index = random_indexes[i, j]\n","    # Récupération de l'image et prédiction de sa classe\n","    image = pred_images[img_index]\n","    probabilities = model.predict(image[None, ...])[0]\n","    predicted_class = label_names[numpy.argmax(probabilities)]\n","\n","    # Affichage avec matplotlib et sa fonction imshow, très pratique en vision\n","    # par ordinateur\n","    ax[i * 2, j].imshow(image)\n","    ax[i * 2, j].set_title(f\"Exemple {img_index}\")\n","    ax[i * 2, j].axis('off')\n","\n","    # Affichage de la distribution de prédiction sur la ligne d'en dessous\n","    ax[i * 2 + 1, j].bar(label_names, probabilities)"],"execution_count":null,"outputs":[]}]}