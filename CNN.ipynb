{"cells":[{"cell_type":"markdown","metadata":{"id":"Be5uBRdgbhey"},"source":["# CNNs avec Keras sur des données de paysage"]},{"cell_type":"markdown","metadata":{"id":"7-diCsctWfSh"},"source":["## Vérification de l'utilisation de GPU\n","\n","Allez dans le menu `Exécution > Modifier le type d'execution` et vérifiez que l'on est bien en Python 3 et que l'accélérateur matériel est configuré sur « GPU »."]},{"cell_type":"code","execution_count":1,"metadata":{"id":"-S9vf7TtjjMa"},"outputs":[{"name":"stdout","output_type":"stream","text":["/bin/sh: 1: nvidia-smi: not found\n"]}],"source":["!nvidia-smi"]},{"cell_type":"markdown","metadata":{"id":"N5hheTPDcdqN"},"source":["## Import des librairies nécessaires"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"SvZJ4yH6cNHE"},"outputs":[],"source":["import itertools\n","import os\n","import pathlib\n","import random\n","import typing\n","\n","import cv2\n","import matplotlib.pyplot as plt\n","import numpy\n","import pandas as pd\n","import seaborn\n","import sklearn.utils\n","import sklearn.metrics\n","import tensorflow.keras as keras"]},{"cell_type":"markdown","metadata":{"id":"9zCSZcuhczAn"},"source":["## Préparation des données\n","\n","Pour charger nos données, nous allons combiner plusieurs libraires : [OpenCV](https://opencv.org/), [NumPy](https://numpy.org/) et [scikit-learn](https://scikit-learn.org/stable/). Ces librairies seront appelées depuis la fonction `get_images`.\n","\n","Après avoir chargé chaque image, nous allons passer leur canaux en RGB puis les redimensionner à 150x150, enfin, par défaut, nous retournerons un dataset mélangé grâce à [`sklearn.utils.shuffle`](https://scikit-learn.org/stable/modules/generated/sklearn.utils.shuffle.html).\n","\n","*Complétez la fonction `get_images` qui va chercher les images dans `dir_path` contenant un dossier par classe. Chaque dossier de classe contient l'ensemble des images de cette classe. Il vous faut attribuer le label correct à chaque image.*"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"-kv62rzC3wIO"},"outputs":[],"source":["label_names = [\"convolvulaceae\",\"monimiaceae\",\"amborella\",\"castanea\",\"desmodium\",\"eugenia\",\n","              \"laurus\",\"litsea\",\"magnolia\",\"rubus\",\"ulmus\"]\n","\n","def get_images(filename):\n","\n","  df=pd.read_csv(filename)\n","  images = []\n","  labels = []\n","\n","  for i in range(df[\"label\"]):\n","    path=df[\"im_path\"][i]\n","\n","    image=cv2.imread(path)\n","    images.append(image)\n","\n","    label=df[\"label\"][i]\n","    labels.append(label)\n","\n","  return images,labels\n","\n","label_to_index = {l: i for i, l in enumerate(label_names)}"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["     Unnamed: 0     label                                img_path   bord  \\\n","0             0  castanea  dataset/Train/castanea/castarea096.jpg  dente   \n","1             1  castanea  dataset/Train/castanea/castarea100.jpg  dente   \n","2             2  castanea  dataset/Train/castanea/castarea085.jpg  dente   \n","3             3  castanea  dataset/Train/castanea/castarea082.jpg  dente   \n","4             4  castanea  dataset/Train/castanea/castarea099.jpg  dente   \n","..          ...       ...                                     ...    ...   \n","215         215     rubus        dataset/Train/rubus/rubus100.jpg  dente   \n","216         216     rubus        dataset/Train/rubus/rubus085.jpg  dente   \n","217         217     rubus        dataset/Train/rubus/rubus089.jpg  dente   \n","218         218     rubus        dataset/Train/rubus/rubus083.jpg  dente   \n","219         219     rubus        dataset/Train/rubus/rubus099.jpg  dente   \n","\n","    phyllotaxie type_feuille ligneux  \n","0       alterne       simple     oui  \n","1       alterne       simple     oui  \n","2       alterne       simple     oui  \n","3       alterne       simple     oui  \n","4       alterne       simple     oui  \n","..          ...          ...     ...  \n","215     alterne     composee     oui  \n","216     alterne     composee     oui  \n","217     alterne     composee     oui  \n","218     alterne     composee     oui  \n","219     alterne     composee     oui  \n","\n","[220 rows x 7 columns]\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>label</th>\n","      <th>img_path</th>\n","      <th>bord</th>\n","      <th>phyllotaxie</th>\n","      <th>type_feuille</th>\n","      <th>ligneux</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>castanea</td>\n","      <td>dataset/Train/castanea/castarea096.jpg</td>\n","      <td>dente</td>\n","      <td>alterne</td>\n","      <td>simple</td>\n","      <td>oui</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>castanea</td>\n","      <td>dataset/Train/castanea/castarea100.jpg</td>\n","      <td>dente</td>\n","      <td>alterne</td>\n","      <td>simple</td>\n","      <td>oui</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>castanea</td>\n","      <td>dataset/Train/castanea/castarea085.jpg</td>\n","      <td>dente</td>\n","      <td>alterne</td>\n","      <td>simple</td>\n","      <td>oui</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>castanea</td>\n","      <td>dataset/Train/castanea/castarea082.jpg</td>\n","      <td>dente</td>\n","      <td>alterne</td>\n","      <td>simple</td>\n","      <td>oui</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>castanea</td>\n","      <td>dataset/Train/castanea/castarea099.jpg</td>\n","      <td>dente</td>\n","      <td>alterne</td>\n","      <td>simple</td>\n","      <td>oui</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>215</th>\n","      <td>215</td>\n","      <td>rubus</td>\n","      <td>dataset/Train/rubus/rubus100.jpg</td>\n","      <td>dente</td>\n","      <td>alterne</td>\n","      <td>composee</td>\n","      <td>oui</td>\n","    </tr>\n","    <tr>\n","      <th>216</th>\n","      <td>216</td>\n","      <td>rubus</td>\n","      <td>dataset/Train/rubus/rubus085.jpg</td>\n","      <td>dente</td>\n","      <td>alterne</td>\n","      <td>composee</td>\n","      <td>oui</td>\n","    </tr>\n","    <tr>\n","      <th>217</th>\n","      <td>217</td>\n","      <td>rubus</td>\n","      <td>dataset/Train/rubus/rubus089.jpg</td>\n","      <td>dente</td>\n","      <td>alterne</td>\n","      <td>composee</td>\n","      <td>oui</td>\n","    </tr>\n","    <tr>\n","      <th>218</th>\n","      <td>218</td>\n","      <td>rubus</td>\n","      <td>dataset/Train/rubus/rubus083.jpg</td>\n","      <td>dente</td>\n","      <td>alterne</td>\n","      <td>composee</td>\n","      <td>oui</td>\n","    </tr>\n","    <tr>\n","      <th>219</th>\n","      <td>219</td>\n","      <td>rubus</td>\n","      <td>dataset/Train/rubus/rubus099.jpg</td>\n","      <td>dente</td>\n","      <td>alterne</td>\n","      <td>composee</td>\n","      <td>oui</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>220 rows × 7 columns</p>\n","</div>"],"text/plain":["     Unnamed: 0     label                                img_path   bord  \\\n","0             0  castanea  dataset/Train/castanea/castarea096.jpg  dente   \n","1             1  castanea  dataset/Train/castanea/castarea100.jpg  dente   \n","2             2  castanea  dataset/Train/castanea/castarea085.jpg  dente   \n","3             3  castanea  dataset/Train/castanea/castarea082.jpg  dente   \n","4             4  castanea  dataset/Train/castanea/castarea099.jpg  dente   \n","..          ...       ...                                     ...    ...   \n","215         215     rubus        dataset/Train/rubus/rubus100.jpg  dente   \n","216         216     rubus        dataset/Train/rubus/rubus085.jpg  dente   \n","217         217     rubus        dataset/Train/rubus/rubus089.jpg  dente   \n","218         218     rubus        dataset/Train/rubus/rubus083.jpg  dente   \n","219         219     rubus        dataset/Train/rubus/rubus099.jpg  dente   \n","\n","    phyllotaxie type_feuille ligneux  \n","0       alterne       simple     oui  \n","1       alterne       simple     oui  \n","2       alterne       simple     oui  \n","3       alterne       simple     oui  \n","4       alterne       simple     oui  \n","..          ...          ...     ...  \n","215     alterne     composee     oui  \n","216     alterne     composee     oui  \n","217     alterne     composee     oui  \n","218     alterne     composee     oui  \n","219     alterne     composee     oui  \n","\n","[220 rows x 7 columns]"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["get_images(\"data_train_labeled.csv\")"]},{"cell_type":"markdown","metadata":{"id":"12Co3AuagRdQ"},"source":["## Appel à `get_images`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mlWHQMqbgUi_"},"outputs":[],"source":["images, labels, file_paths = "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z9CFPgYahZ-_"},"outputs":[],"source":["print(f\"Forme des images : {images.shape}\")\n","print(f\"Forme des labels : {labels.shape}\")\n","print(f\"Forme des chemins : {file_paths.shape}\")\n","\n","seaborn.countplot(x=labels)\n","plt.title(\"Décomptes des différents labels\")\n","plt.ylabel(\"Décompte\")\n","plt.xlabel(\"Label\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hRP8sepdhh8I"},"outputs":[],"source":["# Création de la grille de sous-plots. On donne l'argument figsize pour agrandir\n","# la taille de la figure qui est petite par défaut\n","f, ax = plt.subplots(5, 5, figsize=(15, 15))\n","\n","# On choisit 25 indices au hasard, sans replacement (on ne veut pas afficher la\n","# même image deux fois)\n","random_indexes = numpy.random.choice(images.shape[0],\n","                                     size=(5, 5),\n","                                     replace=False)\n","\n","for i in range(5):\n","  for j in range(5):\n","    img_index = random_indexes[i, j]\n","    image = images[img_index]\n","    label = label_names[labels[img_index]]\n","\n","    # Affichage avec matplotlib et sa fonction imshow, très pratique en vision par\n","    # ordinateur\n","    ax[i, j].imshow(image)\n","    ax[i, j].set_title(f\"Exemple {img_index} ({label})\")\n","    ax[i, j].axis('off')"]},{"cell_type":"markdown","metadata":{"id":"8JOKqXxDP5jB"},"source":["## Création du modèle\n","\n","Voici un exemple de CNN « minimaliste »"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qFvhX0LZjZw3"},"outputs":[],"source":["# Initialisation et définition du modéle\n","\n","# Le modèle est un empilement de couches où le flux de données est séquentiel\n","model = keras.models.Sequential()\n","# Une première couche de 1 convolutions de 3x3 pixels\n","model.add(keras.layers.Conv2D(1,\n","                              kernel_size=(3, 3),\n","                              activation=\"relu\",\n","                              input_shape=(150, 150, 3)))\n","# Une couche de max pooling\n","model.add(keras.layers.MaxPool2D(3,3))\n","\n","# Une couche de manipulation des tenseurs : suppression de toutes les dimensions\n","# sauf celle de batch et une autre qui contient toutes les valeurs\n","model.add(keras.layers.Flatten())\n","\n","# Une couche de sortie dense avec 6 neurones et un softmax comme activation\n","model.add(keras.layers.Dense(6, activation=\"softmax\"))\n","\n","# Compilation du modèle avec la définition de la fonction de perte\n","model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n","              loss=\"sparse_categorical_crossentropy\",\n","              metrics=[\"accuracy\"])\n","\n","# Affichage d'un résumé du modèle\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"woNSPikeU_xl"},"source":["## Apprentissage\n","\n","Apprenons ce modèle sur nos données ! Dans un premier temps, nous entraînons sur une seule epoch pour simplement vérifier que notre modèle est opérationnel."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-vg7kkCCiyB_"},"outputs":[],"source":["# Apprentissage du modèle\n","training_history = model.fit(images, labels, epochs=1, validation_split=0.30)"]},{"cell_type":"markdown","metadata":{"id":"3ffuXmAvTuqF"},"source":["## Améliorez cette performance\n","\n","Inspirez-vous du modèle précédent en rajoutant des couches, en faisant des couches plus petites ou plus grosses.\n","\n","Visez entre 10 et 20 itérations et mois de 1 minute par itération (pour des raisons évidentes).\n","\n","On peut considérer l'utilisation d'une couche de dropout juste avant la dernière couche dense pour améliorer la régularisation.\n","\n","On peut obtenir une précision supérieure à 70% sur la base de validation en un temps raisonnable.\n","\n","La solution proposée prend $\\approx$ 45 secondes par itération pendant 15 itérations et atteint aux alentour de 85% d'accuracy sur la base de validation."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K-j7dwcWUdZx"},"outputs":[],"source":["# Vos améliorations ici\n","model = keras.models.Sequential()\n","model.add(keras.layers.Conv2D(10,\n","                              kernel_size=(3, 3),\n","                              activation=\"relu\",\n","                              input_shape=(150, 150, 3)))\n","model.add(keras.layers.MaxPool2D(3,3))\n","model.add(keras.layers.Flatten())\n","model.add(keras.layers.Dense(6, activation=\"softmax\"))\n","model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n","              loss=\"sparse_categorical_crossentropy\",\n","              metrics=[\"accuracy\"])\n","\n","# Affichage d'un résumé du modèle\n","model.summary()\n","\n","# Apprentissage du modèle\n","training = model.fit(images, labels, epochs=10, validation_split=0.30)\n","\n","\n","# Plot des métriques d'entraînement\n","def plot_metrics(history) -> None:\n","  plt.plot(training.history[\"accuracy\"])\n","  plt.plot(training.history[\"val_accuracy\"])\n","  plt.title(\"Accuracy du modèle\")\n","  plt.ylabel(\"Accuracy\")\n","  plt.xlabel(\"Epoch\")\n","  plt.legend([\"Entraînement\", \"Validation\"], loc=\"upper left\")\n","  plt.show()\n","\n","  plt.plot(training.history[\"loss\"])\n","  plt.plot(training.history[\"val_loss\"])\n","  plt.title(\"Perte du modèle\")\n","  plt.ylabel(\"Perte\")\n","  plt.xlabel(\"Epoch\")\n","  plt.legend([\"Entraînement\", \"Validation\"], loc=\"upper right\")\n","  plt.show()\n","\n","\n","plot_metrics(training.history)"]},{"cell_type":"markdown","metadata":{"id":"eGazvkPxP0oX"},"source":["### Solution"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8bIuRTZYAnWR"},"outputs":[],"source":["conv2d_params = dict(kernel_size=(3,3),\n","                     activation=\"relu\",\n","                     kernel_initializer=\"orthogonal\",\n","                     padding=\"same\")\n","\n","dense_params = dict(activation=\"relu\", kernel_initializer=\"orthogonal\")\n","\n","model = keras.models.Sequential()\n","model.add(keras.layers.Conv2D(200, input_shape=(150, 150, 3), **conv2d_params))\n","model.add(keras.layers.MaxPool2D(2, 2, padding=\"same\"))\n","model.add(keras.layers.Conv2D(200, **conv2d_params))\n","model.add(keras.layers.MaxPool2D(2, 2, padding=\"same\"))\n","model.add(keras.layers.Conv2D(200, **conv2d_params))\n","model.add(keras.layers.MaxPool2D(2, 2, padding=\"same\"))\n","model.add(keras.layers.Conv2D(200, **conv2d_params))\n","model.add(keras.layers.MaxPool2D(2, 2, padding=\"same\"))\n","model.add(keras.layers.Conv2D(200, **conv2d_params))\n","model.add(keras.layers.MaxPool2D(2, 2, padding=\"same\"))\n","model.add(keras.layers.Conv2D(200, **conv2d_params))\n","model.add(keras.layers.MaxPool2D(2, 2, padding=\"same\"))\n","model.add(keras.layers.Conv2D(200, **conv2d_params))\n","model.add(keras.layers.Flatten())\n","model.add(keras.layers.Dropout(rate=0.2))\n","model.add(keras.layers.Dense(200, **dense_params))\n","model.add(keras.layers.Dropout(rate=0.2))\n","model.add(keras.layers.Dense(100, **dense_params))\n","model.add(keras.layers.Dropout(rate=0.2))\n","model.add(keras.layers.Dense(50, **dense_params))\n","model.add(keras.layers.Dropout(rate=0.2))\n","model.add(keras.layers.Dense(6,\n","                             activation=\"softmax\",\n","                             kernel_initializer=\"orthogonal\"))\n","\n","model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n","              loss=\"sparse_categorical_crossentropy\",\n","              metrics=[\"accuracy\"])\n","\n","# Affichage d'un résumé du modèle\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3PsIIXF0hzy5"},"outputs":[],"source":["# Apprentissage du modèle\n","training = model.fit(images,\n","                     labels,\n","                     epochs=15,\n","                     validation_split=0.30,\n","                     batch_size=128)\n","\n","# Visualisation des métriques d'entrainement\n","plot_metrics(training.history)"]},{"cell_type":"markdown","metadata":{"id":"hb_IT9QWeYPh"},"source":["## Évaluation des performances sur l'ensemble de test\n","\n","Dans le dossier `seg_test` se trouve un ensemble de données qui n'ont jamais été vues durant l'apprentissage.\n","\n","On utilisera la méthode `evaluate(X, y)` du modèle pour évaluer la qualité de nos prédictions sur ce dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pJubx-J7i882"},"outputs":[],"source":["test_images,test_labels, test_file_paths = get_images(\n","    pathlib.Path(\"dataset-landscape\") / \"seg_test\")\n","model.evaluate(test_images, test_labels, verbose=1)"]},{"cell_type":"markdown","metadata":{"id":"RYPaPc0lpe0B"},"source":["## Analyse d'erreur\n","\n","On affiche la matrice de confusion puis on regarde des images mal classées."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mfOlRq1Ep3KD"},"outputs":[],"source":["def analyze_preds(preds, labels):\n","  confusion_matrix = sklearn.metrics.confusion_matrix(preds,\n","                                                      labels,\n","                                                      normalize=\"true\")\n","  seaborn.heatmap(confusion_matrix,\n","                  cmap=\"rocket_r\",\n","                  xticklabels=label_names,\n","                  yticklabels=label_names)\n","  plt.title(\"Matrice de confusion\")\n","  plt.show()\n","\n","  seaborn.countplot(x=list(map(lambda x: label_names[x], preds)))\n","  plt.title(\"Décomptes des classes prédites\")\n","  plt.ylabel(\"Décompte\")\n","  plt.xlabel(\"Class\")\n","  plt.show()\n","\n","\n","test_pred = numpy.argmax(model.predict(test_images), axis=-1)\n","analyze_preds(test_pred, test_labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hLUCp97BeUxu"},"outputs":[],"source":["def plot_mistakes(predicted_class: str, true_class: str) -> None:\n","  print(f\"Prédiction : {predicted_class}, classe réelle : {true_class}\")\n","  mistakes = test_images[(test_pred == label_to_index[predicted_class])\n","                         & (test_labels == label_to_index[true_class])]\n","  random_indexes = numpy.random.choice(mistakes.shape[0],\n","                                       size=min(mistakes.shape[0], 25),\n","                                       replace=False)\n","  grid_indexes = itertools.product(range(5), repeat=2)\n","\n","  _, ax = plt.subplots(5, 5, figsize=(15, 15))\n","  for img_index, (i, j) in zip(random_indexes, grid_indexes):\n","    ax[i, j].imshow(mistakes[img_index])\n","    ax[i, j].axis(\"off\")\n","  plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"43kc6Wgd9bkC"},"outputs":[],"source":["# Plot les images prédites glacier alors qu'elles ont un label montagne\n","plot_mistakes(\"glacier\", \"mountain\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_QyUe_6T_vL8"},"outputs":[],"source":["# Plot les images prédites glacier alors qu'elles ont un label mer\n","plot_mistakes(\"glacier\", \"sea\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eAgJItMSDE2-"},"outputs":[],"source":["# Plot les images prédites bâtiment alors qu'elles ont un label mer\n","plot_mistakes(\"buildings\", \"sea\")"]},{"cell_type":"markdown","metadata":{"id":"5VrH5FRb_OBy"},"source":["## Transfert d'apprentissage"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QCDC0Hw6_Qrn"},"outputs":[],"source":["base_model = keras.applications.EfficientNetB7(include_top=False,\n","                                               weights=\"imagenet\",\n","                                               input_shape=(150, 150, 3))\n","\n","base_model.trainable = False\n","\n","model = keras.Sequential(\n","    [base_model,\n","     keras.layers.SpatialDropout2D(0.1),\n","     keras.layers.Conv2D(1024, 1, activation=\"relu\"),\n","     keras.layers.SpatialDropout2D(0.1),\n","     keras.layers.Conv2D(256, 1, activation=\"relu\"),\n","     keras.layers.SpatialDropout2D(0.1),\n","     keras.layers.Conv2D(64, 1, activation=\"relu\"),\n","     keras.layers.SpatialDropout2D(0.1),\n","     keras.layers.Conv2D(16, 1, activation=\"relu\"),\n","     keras.layers.SpatialDropout2D(0.1),\n","     keras.layers.Flatten(),\n","     keras.layers.Dense(6, activation=\"softmax\", kernel_regularizer=\"l2\")])\n","\n","model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n","              loss=\"sparse_categorical_crossentropy\",\n","              metrics=[\"accuracy\"])\n","\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uzYvqXA6A4_b"},"outputs":[],"source":["training = model.fit(images,\n","                     labels,\n","                     epochs=5,\n","                     validation_split=0.30,\n","                     batch_size=512)\n","\n","plot_metrics(training.history)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9W-qBnuTAegR"},"outputs":[],"source":["model.evaluate(test_images, test_labels, verbose=1)\n","test_preds = numpy.argmax(model.predict(test_images), axis=-1)\n","analyze_preds(test_preds, test_labels)\n","plot_mistakes(\"glacier\", \"mountain\")\n","plot_mistakes(\"glacier\", \"sea\")\n","plot_mistakes(\"buildings\", \"sea\")"]},{"cell_type":"markdown","metadata":{"id":"v4Q5NiBKjO6X"},"source":["## Prédire dans des condition « réelles »\n","\n","Dans le dossier `seg_pred` se trouvent des images non-annotées. On ne peut donc pas évaluer correctement les performances sur cet ensemble. \n","\n","Cependant, on peut afficher des photos et les probabilités que notre modèle attribue à chaque classe."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7yPf4WcytFzQ"},"outputs":[],"source":["pred_images, _, pred_file_paths = get_images(\n","    pathlib.Path(\"dataset-landscape\") / \"seg_pred\")\n","pred_images.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iMLmuIqvWAS6"},"outputs":[],"source":["# Création de la grille de sous-plots. On donne l'argument figsize pour agrandir\n","# la taille de la figure qui est petite par défaut\n","_, ax = plt.subplots(10, 5, figsize=(30, 45))\n","\n","# On choisit 25 indices au hasard, sans replacement (on ne veut pas afficher la\n","# même image deux fois)\n","random_indexes = numpy.random.choice(pred_images.shape[0],\n","                                     size=(5, 5),\n","                                     replace=False)\n","\n","for i in range(5):\n","  for j in range(5):\n","    img_index = random_indexes[i, j]\n","    # Récupération de l'image et prédiction de sa classe\n","    image = pred_images[img_index]\n","    probabilities = model.predict(image[None, ...])[0]\n","    predicted_class = label_names[numpy.argmax(probabilities)]\n","\n","    # Affichage avec matplotlib et sa fonction imshow, très pratique en vision\n","    # par ordinateur\n","    ax[i * 2, j].imshow(image)\n","    ax[i * 2, j].set_title(f\"Exemple {img_index}\")\n","    ax[i * 2, j].axis('off')\n","\n","    # Affichage de la distribution de prédiction sur la ligne d'en dessous\n","    ax[i * 2 + 1, j].bar(label_names, probabilities)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["VbswqLLSgMzK","c6jAWFPyP85p","eGazvkPxP0oX"],"machine_shape":"hm","private_outputs":true,"provenance":[{"file_id":"1xLFNAWBJxmp0GBcRhmwKfZUbewBDq4hz","timestamp":1637764472783},{"file_id":"1wS56Bvj0KNGqMHIviwd2Y9uwYnUYkT5b","timestamp":1570893367950},{"file_id":"14MjAMPKQD3LIncUn2YEHJ3fBq8K2upuq","timestamp":1558960238747}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.8.10 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"vscode":{"interpreter":{"hash":"31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"}}},"nbformat":4,"nbformat_minor":0}
